{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "    name = url.split('/')[-1]\n",
    "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "    img = PIL.Image.open(image_path)\n",
    "    if max_dim:\n",
    "        img.thumbnail((max_dim, max_dim))\n",
    "    return np.array(img)\n",
    "\n",
    "def get_image(image_path, max_dim=None):\n",
    "    img = PIL.Image.open(image_path)\n",
    "    img = img.convert('RGB')\n",
    "    if max_dim:\n",
    "        img.thumbnail((max_dim, max_dim))\n",
    "    return np.array(img)\n",
    "\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "    img = 255*(img + 1.0)/2.0\n",
    "    return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "    display.display(PIL.Image.fromarray(np.array(img)))\n",
    "\n",
    "\n",
    "def show_save_img(img, epoch):\n",
    "    display.clear_output(wait=True)\n",
    "    p_img = PIL.Image.fromarray(np.array(img))\n",
    "    display.display(p_img)\n",
    "    p_img.save('./output/image_{:04d}.png'.format(epoch))    \n",
    "\n",
    "    \n",
    "original_img = get_image('./source10.png')\n",
    "# original_img = download(url)\n",
    "print(original_img.shape)\n",
    "show(original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximize the activations of these layers\n",
    "names = ['mixed5', 'mixed6']\n",
    "names = ['mixed3', 'mixed8']\n",
    "# names = ['mixed3']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dream_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(img, model):\n",
    "    # Pass forward the image through the model to retrieve the activations.\n",
    "    # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "\n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return  tf.reduce_sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.total_variation_weight = 0\n",
    "\n",
    "    @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "    )\n",
    "    def __call__(self, img, steps, step_size):\n",
    "        print(\"Tracing\")\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # This needs gradients relative to `img`\n",
    "                # `GradientTape` only watches `tf.Variable`s by default\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "                loss += self.total_variation_weight*tf.image.total_variation(img)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "        return loss, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepdream = DeepDream(dream_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deep_dream_simple(img, begin = 0, steps=100, batch_size=100, alpha=0.01):\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    alpha = tf.convert_to_tensor(alpha)\n",
    "\n",
    "    for epoch in range(begin, begin + steps):\n",
    "        loss, img = deepdream(img, batch_size, tf.constant(alpha))\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            show_save_img(deprocess(img), epoch)\n",
    "            print (\"Step {}, loss {}\".format(epoch, loss))\n",
    "\n",
    "    show_save_img(deprocess(img), epoch)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = run_deep_dream_simple(img=original_img, begin = 0, steps=100, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
